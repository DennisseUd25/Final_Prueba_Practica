{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11131715,"sourceType":"datasetVersion","datasetId":6942633},{"sourceId":11139504,"sourceType":"datasetVersion","datasetId":6948459}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PYTHON Text Analysis: Preprocesamiento\n### Objetivos de aprendizaje\n\nAprender los pasos habituales para el preprocesamiento de datos de texto, así como las operaciones específicas para el preprocesamiento de datos de Twitter.\nConocer los paquetes de PNL más utilizados y lo que son capaces de hacer.\nComprender los tokenizadores y cómo han cambiado desde la aparición de los modelos de lenguaje de gran tamaño.\n\n### Secciones\nEn estos tres talleres, aprenderemos a contruir los componentes básicos para realizar análisis de texto en Python. Estas técnicas pertenecen al ámbito del Procesamiento del Lenguaje Natural (NLP). NLP es un campo que se ocupa de identificar y extraer patrones del lenguaje, principalmente en textos escritos. A lo largo de la serie de talleres, interactuaremos con diversos paquetes para realizar análisis de texto: desde simples métodos de cadenas para paquetes específicos NLP, como *nltk*, *spaCy* y los más recientes sobre Grandes Modelos de Lenguaje (*BERT*).\n\nAhora, vamos a tener instalados correctamente estos paquetes ante de introducirnos en la materia.","metadata":{}},{"cell_type":"code","source":"#Instalar los siguientes paquetes/modelos\n%pip install NLTK\n%pip install transformers\n%pip install spaCy\n!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:40:08.252827Z","iopub.execute_input":"2025-03-25T16:40:08.253263Z","iopub.status.idle":"2025-03-25T16:41:04.173398Z","shell.execute_reply.started":"2025-03-25T16:40:08.253234Z","shell.execute_reply":"2025-03-25T16:41:04.172123Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: NLTK in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from NLTK) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.11.0a2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spaCy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spaCy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spaCy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spaCy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spaCy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spaCy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spaCy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spaCy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spaCy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/usr/lib/python3.10/socket.py\", line 955, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno -3] Temporary failure in name resolution\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 704, in connect\n    self.sock = sock = self._new_conn()\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7be3cce315a0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7be3cce315a0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n    setup_cli()\n  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 87, in setup_cli\n    command(prog_name=COMMAND)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 743, in main\n    return _main(\n  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 198, in _main\n    rv = self.invoke(ctx)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 698, in wrapper\n    return callback(**use_params)\n  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/download.py\", line 44, in download_cli\n    download(model, direct, sdist, *ctx.args)\n  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/download.py\", line 85, in download\n    compatibility = get_compatibility()\n  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/download.py\", line 130, in get_compatibility\n    r = requests.get(about.__compatibility__)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 73, in get\n    return request(\"get\", url, params=params, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7be3cce315a0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\"))\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Preprocesamiento\nEn esta primera parte, abordaremos el primer paso para el análisis de texto. Nuestro objetivo es convertir los datos de texto en bruto y desordenados en un formato coherente. Este proceso suele denominarse **preprocesamiento, limpieza o normalización de texto.**\nNotaras que al final del preprocesamiento, nuestra data aun está en un formato que leer y entender. En la perte 2 y 3, comenzaremos nuestra incursión en la conversión de los datos de texto en una representación numérica, un formato que puede ser más facilmente manejable por los computadores.\n\n**Pregunta:** Vamos a pausar por un minuto para reflexionar sobre tus experiencias previas trabajando con datos de texto.\n\n* ¿Cuál es el formato de los datos de texto con los que ha interactuado (texto sin formato, CSV o XML)?\n* ¿De dónde proceden (corpus estructurado, extraídos de la web, datos de encuestas)?\n* ¿Están desordenados (es decir, tienen un formato coherente)?\n\n## Procesos Comunes\nEl preprocesamiento no es algo que podamos lograr con una sola línea de código. A menudo empezamos familiarizándonos con los datos y, sobre en el camino, vamos comprendiendo mejor la granularidad del preprocesamiento que queremos aplicar.\nNormalmente, empezamos aplicando un conjunto de procesos de uso común para limpiar los datos. Estas operaciones no alteran sustancialmente la forma o el significado de los datos, sino que sirven como procedimiento normalizado para remodelar los datos en un formato coherente.\nEl siguiente proceso, por ejemplo, aplicamos habitualmente para procesar textos en ingles de varios generos. Esta operaciones pueden ser realizadas usando funciones en Python, como: métodos **String** y expreciones regulares.\n* Poner el texto en minúsculas.\n* Eliminar los signos de puntuación.\n* Eliminar los espacios en blanco.\n* Eliminar las palabras vacías.\n\nDespués de iniciar el tratamiento, podemos optar por realizar procesos específicos para cada tarea, cuyos detalles suelen depender de la tarea posterior que queramos realizar y de la naturaleza de los datos textuales (es decir, de sus características estilísticas y lingüísticas).\n\nAntes de iniciar estas operaciones, vamos a revisar nuestros datos.\n\n## Importar los datos de texto\nLos datos de texto con los que estaremos trabajando son un archivo CSV. Contiene Tweets sobre aerolíneas estadounidenses, desechados desde febrero del 2015.\n\nVamos a leer el archivo *airline_tweets.csv* en dataframe con *pandas*.","metadata":{}},{"cell_type":"code","source":"# Importamos la librería pandas\nimport pandas as pd\n\n# Ruta de acceso a los datos\ncsv_path = '/kaggle/input/data-tweets/airline_tweets.csv'\n\n# Especificamos el separador\ntweets = pd.read_csv(csv_path, sep=',')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:41:47.657520Z","iopub.execute_input":"2025-03-25T16:41:47.657870Z","iopub.status.idle":"2025-03-25T16:41:47.792623Z","shell.execute_reply.started":"2025-03-25T16:41:47.657841Z","shell.execute_reply":"2025-03-25T16:41:47.791641Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Mostrar las primero 5 filas\ntweets.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:41:50.349052Z","iopub.execute_input":"2025-03-25T16:41:50.349450Z","iopub.status.idle":"2025-03-25T16:41:50.384258Z","shell.execute_reply.started":"2025-03-25T16:41:50.349420Z","shell.execute_reply":"2025-03-25T16:41:50.383069Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n0  570306133677760513           neutral                        1.0000   \n1  570301130888122368          positive                        0.3486   \n2  570301083672813571           neutral                        0.6837   \n3  570301031407624196          negative                        1.0000   \n4  570300817074462722          negative                        1.0000   \n\n  negativereason  negativereason_confidence         airline  \\\n0            NaN                        NaN  Virgin America   \n1            NaN                     0.0000  Virgin America   \n2            NaN                        NaN  Virgin America   \n3     Bad Flight                     0.7033  Virgin America   \n4     Can't Tell                     1.0000  Virgin America   \n\n  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n0                    NaN     cairdin                 NaN              0   \n1                    NaN    jnardino                 NaN              0   \n2                    NaN  yvonnalynn                 NaN              0   \n3                    NaN    jnardino                 NaN              0   \n4                    NaN    jnardino                 NaN              0   \n\n                                                text tweet_coord  \\\n0                @VirginAmerica What @dhepburn said.         NaN   \n1  @VirginAmerica plus you've added commercials t...         NaN   \n2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n3  @VirginAmerica it's really aggressive to blast...         NaN   \n4  @VirginAmerica and it's a really big bad thing...         NaN   \n\n               tweet_created tweet_location               user_timezone  \n0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>airline_sentiment</th>\n      <th>airline_sentiment_confidence</th>\n      <th>negativereason</th>\n      <th>negativereason_confidence</th>\n      <th>airline</th>\n      <th>airline_sentiment_gold</th>\n      <th>name</th>\n      <th>negativereason_gold</th>\n      <th>retweet_count</th>\n      <th>text</th>\n      <th>tweet_coord</th>\n      <th>tweet_created</th>\n      <th>tweet_location</th>\n      <th>user_timezone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570306133677760513</td>\n      <td>neutral</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>cairdin</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica What @dhepburn said.</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:35:52 -0800</td>\n      <td>NaN</td>\n      <td>Eastern Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570301130888122368</td>\n      <td>positive</td>\n      <td>0.3486</td>\n      <td>NaN</td>\n      <td>0.0000</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>jnardino</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica plus you've added commercials t...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:15:59 -0800</td>\n      <td>NaN</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570301083672813571</td>\n      <td>neutral</td>\n      <td>0.6837</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>yvonnalynn</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:15:48 -0800</td>\n      <td>Lets Play</td>\n      <td>Central Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570301031407624196</td>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Bad Flight</td>\n      <td>0.7033</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>jnardino</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica it's really aggressive to blast...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:15:36 -0800</td>\n      <td>NaN</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570300817074462722</td>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Can't Tell</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>NaN</td>\n      <td>jnardino</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>@VirginAmerica and it's a really big bad thing...</td>\n      <td>NaN</td>\n      <td>2015-02-24 11:14:45 -0800</td>\n      <td>NaN</td>\n      <td>Pacific Time (US &amp; Canada)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"El dataframe tiene una fila por tweet. El texto del tweet se muestra en la columna de texto.\n* *text* (*str*): el texto del tweet.\nOtro metadata que nos interesa incluir:\n* *airline_sentiment* (*str*): el sentimiento del tweet, etiquetado como neutral, positivo o negativo.\n* *airline* (*str*): la aerolínea de que se menciona en el tweet.\n* *retweet count* (*int*): Cuantas veces de retuiteó el tweet.\n\nVeamos algunos de los tweets:","metadata":{}},{"cell_type":"code","source":"print(tweets['text'].iloc[0])\nprint(tweets['text'].iloc[1])\nprint(tweets['text'].iloc[2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:28:47.204714Z","iopub.execute_input":"2025-03-25T16:28:47.205078Z","iopub.status.idle":"2025-03-25T16:28:47.216676Z","shell.execute_reply.started":"2025-03-25T16:28:47.205050Z","shell.execute_reply":"2025-03-25T16:28:47.215405Z"}},"outputs":[{"name":"stdout","text":"@VirginAmerica What @dhepburn said.\n@VirginAmerica plus you've added commercials to the experience... tacky.\n@VirginAmerica I didn't today... Must mean I need to take another trip!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Minúsculas\nReconozcamos que la etiqueta de una palabra es informativa, a menudo no trabajamos en contextos en los que podamos utilizar adecuadamente esta información.\n\nCon mayor frecuencia, el análisis posterior que realizamos no distingue entre mayúsculas y minúsculas. Por ejemplo, en el análisis de frecuencias, queremos tener en cuenta varias formas de la misma palabra. El uso de minúsculas en los datos de texto ayuda en este proceso y simplifica nuestro análisis.\n\nPodemos fácilmente redducir las minúsculas con el método de cadena *.lower()*;  consulte la documentación para ver más funciones útiles.\n\nVamos a aplicarlo al siguiente ejemplo:\n","metadata":{}},{"cell_type":"code","source":"# Print al primer ejemplo\nfirst_example = tweets['text'][108]\nprint(first_example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:28:50.897777Z","iopub.execute_input":"2025-03-25T16:28:50.898308Z","iopub.status.idle":"2025-03-25T16:28:50.904955Z","shell.execute_reply.started":"2025-03-25T16:28:50.898262Z","shell.execute_reply":"2025-03-25T16:28:50.903217Z"}},"outputs":[{"name":"stdout","text":"@VirginAmerica I was scheduled for SFO 2 DAL flight 714 today. Changed to 24th due weather. Looks like flight still on?\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Verifica si todos los caracteres entán en minúsculas\nprint(first_example.islower())\nprint(f\"{'=' * 50}\")\n\n# Convierte a minúsculas\nprint(first_example.lower())\nprint(f\"{'=' * 50}\")\n\n# Convierte a mayúsculas\nprint(first_example.upper())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:28:53.091320Z","iopub.execute_input":"2025-03-25T16:28:53.091809Z","iopub.status.idle":"2025-03-25T16:28:53.100370Z","shell.execute_reply.started":"2025-03-25T16:28:53.091767Z","shell.execute_reply":"2025-03-25T16:28:53.099176Z"}},"outputs":[{"name":"stdout","text":"False\n==================================================\n@virginamerica i was scheduled for sfo 2 dal flight 714 today. changed to 24th due weather. looks like flight still on?\n==================================================\n@VIRGINAMERICA I WAS SCHEDULED FOR SFO 2 DAL FLIGHT 714 TODAY. CHANGED TO 24TH DUE WEATHER. LOOKS LIKE FLIGHT STILL ON?\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Eliminar espacios en blanco\nA veces podemos encontrarnos con textos con espacios en blanco extraños, como espacios, tabuladores y caracteres de nueva línea, algo especialmente habitual cuando el texto procede de páginas web. Antes de entrar en detalles, vamos a presentar brevemente las expresiones regulares (regex) y el paquete *re*.\n\nLas expresiones regulares son un potente método de búsqueda de patrones de cadenas específicos en grandes volúmenes. Tienen una curva de aprendizaje infamemente empinada, pero pueden ser muy eficientes cuando nos hacemos con ellas. Muchos paquetes de NLP se basan en gran medida en regex. Los comprobadores de expresiones regulares, como regex101, son herramientas útiles para comprender y crear expresiones regulares.\n\nNuestro objetivo en este taller no es proporcionar una inmersión profunda (o incluso superficial) en regex; en su lugar, queremos exponerte a ellos para que estés mejor preparado para hacer inmersiones profundas en el futuro.\n\nEl siguiente ejemplo es un poema de William Wordsworth. Como muchos poemas, el texto puede contener saltos de línea adicionales (es decir, caracteres de nueva línea, \\n) que queremos eliminar.\n","metadata":{}},{"cell_type":"code","source":"# Ruta de acceso a los datos\ntext_path = '/kaggle/input/data-tweets/poem_wordsworth.txt'\n\n# Lectura del poema \nwith open(text_path, 'r') as file:\n    text = file.read()\n    file.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:28:57.664794Z","iopub.execute_input":"2025-03-25T16:28:57.665182Z","iopub.status.idle":"2025-03-25T16:28:57.690316Z","shell.execute_reply.started":"2025-03-25T16:28:57.665114Z","shell.execute_reply":"2025-03-25T16:28:57.689155Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Como puedes ver, el poema está formateado como una cadena continua de texto con saltos de línea al final de cada línea, lo que dificulta su lectura.","metadata":{}},{"cell_type":"code","source":"text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:01.792239Z","iopub.execute_input":"2025-03-25T16:29:01.792631Z","iopub.status.idle":"2025-03-25T16:29:01.800640Z","shell.execute_reply.started":"2025-03-25T16:29:01.792600Z","shell.execute_reply":"2025-03-25T16:29:01.799370Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\"I wandered lonely as a cloud\\n\\n\\nI wandered lonely as a cloud\\nThat floats on high o'er vales and hills,\\nWhen all at once I saw a crowd,\\nA host, of golden daffodils;\\nBeside the lake, beneath the trees,\\nFluttering and dancing in the breeze.\\n\\nContinuous as the stars that shine\\nAnd twinkle on the milky way,\\nThey stretched in never-ending line\\nAlong the margin of a bay:\\nTen thousand saw I at a glance,\\nTossing their heads in sprightly dance.\\n\\nThe waves beside them danced; but they\\nOut-did the sparkling waves in glee:\\nA poet could not but be gay,\\nIn such a jocund company:\\nI gazed—and gazed—but little thought\\nWhat wealth the show to me had brought:\\n\\nFor oft, when on my couch I lie\\nIn vacant or in pensive mood,\\nThey flash upon that inward eye\\nWhich is the bliss of solitude;\\nAnd then my heart with pleasure fills,\\nAnd dances with the daffodils.\""},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Una función útil que podemos utilizar para mostrar el poema correctamente es *splitline().* Como su nombre sugiere, divide una secuencia de texto larga en una lista de líneas siempre que haya un carácter de nueva línea.","metadata":{}},{"cell_type":"code","source":"# Divide la cadena de texto en líneas\ntext.splitlines()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:05.307753Z","iopub.execute_input":"2025-03-25T16:29:05.308108Z","iopub.status.idle":"2025-03-25T16:29:05.314844Z","shell.execute_reply.started":"2025-03-25T16:29:05.308078Z","shell.execute_reply":"2025-03-25T16:29:05.313618Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['I wandered lonely as a cloud',\n '',\n '',\n 'I wandered lonely as a cloud',\n \"That floats on high o'er vales and hills,\",\n 'When all at once I saw a crowd,',\n 'A host, of golden daffodils;',\n 'Beside the lake, beneath the trees,',\n 'Fluttering and dancing in the breeze.',\n '',\n 'Continuous as the stars that shine',\n 'And twinkle on the milky way,',\n 'They stretched in never-ending line',\n 'Along the margin of a bay:',\n 'Ten thousand saw I at a glance,',\n 'Tossing their heads in sprightly dance.',\n '',\n 'The waves beside them danced; but they',\n 'Out-did the sparkling waves in glee:',\n 'A poet could not but be gay,',\n 'In such a jocund company:',\n 'I gazed—and gazed—but little thought',\n 'What wealth the show to me had brought:',\n '',\n 'For oft, when on my couch I lie',\n 'In vacant or in pensive mood,',\n 'They flash upon that inward eye',\n 'Which is the bliss of solitude;',\n 'And then my heart with pleasure fills,',\n 'And dances with the daffodils.']"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Volvamos a los datos de nuestros tweets a modo de ejemplo.","metadata":{}},{"cell_type":"code","source":"# Print al segundo ejemplo\nsecond_example = tweets['text'][5]\nsecond_example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:09.418526Z","iopub.execute_input":"2025-03-25T16:29:09.418885Z","iopub.status.idle":"2025-03-25T16:29:09.425256Z","shell.execute_reply.started":"2025-03-25T16:29:09.418855Z","shell.execute_reply":"2025-03-25T16:29:09.424271Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA\""},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"En este caso, en realidad no queremos dividir el tweet en una lista de cadenas. Seguimos esperando una única cadena de texto, pero nos gustaría eliminar por completo el salto de línea de la cadena.\n\nEl método string *.strip()* elimina eficazmente los espacios en ambos extremos del texto. Sin embargo, no funcionará en nuestro ejemplo, ya que el carácter de nueva línea está en medio de la cadena.","metadata":{}},{"cell_type":"code","source":"# Strip sólo ha eliminado el espacio en blanco en ambos extremos\nsecond_example.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:12.558234Z","iopub.execute_input":"2025-03-25T16:29:12.558589Z","iopub.status.idle":"2025-03-25T16:29:12.565583Z","shell.execute_reply.started":"2025-03-25T16:29:12.558562Z","shell.execute_reply":"2025-03-25T16:29:12.564343Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA\""},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Aquí es donde regex podría ser realmente útil.","metadata":{}},{"cell_type":"code","source":"import re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:15.209574Z","iopub.execute_input":"2025-03-25T16:29:15.210095Z","iopub.status.idle":"2025-03-25T16:29:15.216346Z","shell.execute_reply.started":"2025-03-25T16:29:15.210046Z","shell.execute_reply":"2025-03-25T16:29:15.214240Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Ahora, con regex, esencialmente lo estamos llamando para que coincida con un patrón que hemos identificado en los datos de texto, y queremos hacer algunas operaciones a la parte coincidente-extraerla, sustituirla por otra cosa, o eliminarla por completo. Por lo tanto, el funcionamiento de regex podría descomponerse en los siguientes pasos:\n\n* Identificar y escribir el patrón en regex (r'PATTERN')\n* Escribir el reemplazo del patrón ('REPLACEMENT')\n* Llamar a la función regex específica (por ejemplo, re.sub())\n\nEn nuestro ejemplo, el patrón que buscamos es \\s, que es la abreviatura regex de cualquier carácter de espacio en blanco (\\n y \\t incluidos). También añadimos un cuantificador + al final: \\s+. Significa que queremos capturar una o más apariciones del carácter de espacio en blanco.","metadata":{}},{"cell_type":"code","source":"# Escribir un patrón en regex\nblankspace_pattern = r'\\s+'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:20.289267Z","iopub.execute_input":"2025-03-25T16:29:20.289637Z","iopub.status.idle":"2025-03-25T16:29:20.294662Z","shell.execute_reply.started":"2025-03-25T16:29:20.289607Z","shell.execute_reply":"2025-03-25T16:29:20.293348Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"El sustituto de uno o más caracteres de espacio en blanco es exactamente un único espacio en blanco, que es el límite canónico de la palabra en inglés. Cualquier espacio en blanco adicional se reducirá a un único espacio en blanco.","metadata":{}},{"cell_type":"code","source":"# Escribimos un reemplazo para el patrón identificado\nblankspace_repl = ' '","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:23.340108Z","iopub.execute_input":"2025-03-25T16:29:23.340563Z","iopub.status.idle":"2025-03-25T16:29:23.344958Z","shell.execute_reply.started":"2025-03-25T16:29:23.340531Z","shell.execute_reply":"2025-03-25T16:29:23.343744Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"Por último, vamos a juntarlo todo utilizando la función re.sub(), que significa que queremos sustituir un patrón por un reemplazo. La función recibe tres argumentos: el patrón, el reemplazo y la cadena a la que queremos aplicar la función.","metadata":{}},{"cell_type":"code","source":"# Reemplazamos los espacios en blanco con ' '\nclean_text = re.sub(pattern = blankspace_pattern, \n                    repl = blankspace_repl, \n                    string = second_example)\nprint(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:26.136223Z","iopub.execute_input":"2025-03-25T16:29:26.136606Z","iopub.status.idle":"2025-03-25T16:29:26.142174Z","shell.execute_reply.started":"2025-03-25T16:29:26.136572Z","shell.execute_reply":"2025-03-25T16:29:26.140859Z"}},"outputs":[{"name":"stdout","text":"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing. it's really the only bad thing about flying VA\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"¡Ta-da!El carácter de nueva línea ya no está ahí.","metadata":{}},{"cell_type":"markdown","source":"## Eliminar signos de puntuación\nA veces sólo nos interesa analizar los caracteres alfanuméricos (es decir, las letras y los números), en cuyo caso es posible que queramos eliminar los signos de puntuación.\nEl módulo string contiene una lista de signos de puntuación predefinidos. Vamos a imprimirlos.","metadata":{}},{"cell_type":"code","source":"# Cargamos una lista predefinida de signos de puntuación\nfrom string import punctuation\nprint(punctuation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:30.069956Z","iopub.execute_input":"2025-03-25T16:29:30.070372Z","iopub.status.idle":"2025-03-25T16:29:30.076366Z","shell.execute_reply.started":"2025-03-25T16:29:30.070340Z","shell.execute_reply":"2025-03-25T16:29:30.074615Z"}},"outputs":[{"name":"stdout","text":"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"En la práctica, para eliminar estos caracteres de puntuación, podemos simplemente iterar sobre el texto y eliminar los caracteres encontrados en la lista, como se muestra a continuación en la función remove_punct.","metadata":{}},{"cell_type":"code","source":"def remove_punct(text):\n    '''Remove punctuation marks in input text'''\n    \n    # Selecionar caracteres no puntuables\n    no_punct = []\n    for char in text:\n        if char not in punctuation:\n            no_punct.append(char)\n\n    # Unir los caracteres en una cadena\n    text_no_punct = ''.join(no_punct)   \n    \n    return text_no_punct","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:33.264815Z","iopub.execute_input":"2025-03-25T16:29:33.265230Z","iopub.status.idle":"2025-03-25T16:29:33.271208Z","shell.execute_reply.started":"2025-03-25T16:29:33.265178Z","shell.execute_reply":"2025-03-25T16:29:33.269715Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"Vamos aplicar la función al ejemplo siguiente.","metadata":{}},{"cell_type":"code","source":"# Print al tercer ejemplo\nthird_example = tweets['text'][20]\nprint(third_example)\nprint(f\"{'=' * 50}\")\n\n# Aplicar la función\nremove_punct(third_example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:37.335752Z","iopub.execute_input":"2025-03-25T16:29:37.336157Z","iopub.status.idle":"2025-03-25T16:29:37.344929Z","shell.execute_reply.started":"2025-03-25T16:29:37.336098Z","shell.execute_reply":"2025-03-25T16:29:37.343875Z"}},"outputs":[{"name":"stdout","text":"@VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select???\n==================================================\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select'"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"Vamos a tratar con otro tweet. ¿Qué has notado?","metadata":{}},{"cell_type":"code","source":"# Print otro tweet\nprint(tweets['text'][100])\nprint(f\"{'=' * 50}\")\n\n# Aplicamos la función\nremove_punct(tweets['text'][100])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:41.437133Z","iopub.execute_input":"2025-03-25T16:29:41.437515Z","iopub.status.idle":"2025-03-25T16:29:41.446928Z","shell.execute_reply.started":"2025-03-25T16:29:41.437487Z","shell.execute_reply":"2025-03-25T16:29:41.444990Z"}},"outputs":[{"name":"stdout","text":"@VirginAmerica trying to add my boy Prince to my ressie. SF this Thursday @VirginAmerica from LAX http://t.co/GsB2J3c4gM\n==================================================\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'VirginAmerica trying to add my boy Prince to my ressie SF this Thursday VirginAmerica from LAX httptcoGsB2J3c4gM'"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"¿Qué pasa con el siguiente ejemplo?","metadata":{}},{"cell_type":"code","source":"# Print a un texto con contracturas\ncontraction_text = \"We've got quite a bit of punctuation here, don't we?!? #Python @D-Lab.\"\n\n# Aplicamos la función\nremove_punct(contraction_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:43.840589Z","iopub.execute_input":"2025-03-25T16:29:43.840988Z","iopub.status.idle":"2025-03-25T16:29:43.847246Z","shell.execute_reply.started":"2025-03-25T16:29:43.840949Z","shell.execute_reply":"2025-03-25T16:29:43.846087Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'Weve got quite a bit of punctuation here dont we Python DLab'"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"**Warning:** En muchos casos, queremos eliminar los signos de puntuación después de la tokenización, de lo que hablaremos dentro de un minuto. Esto nos indica que el orden de preprocesamiento es una cuestión importante.","metadata":{}},{"cell_type":"markdown","source":"## Reto 1: Preprocesamiento con múltiples pasos\nHasta ahora hemos aprendido algunas operaciones de preprocesamiento, ¡vamos a juntarlas en una función! Esta función será muy útil si trabajas con datos de texto en inglés y quieres preprocesarlos con una sola función.\n\nA continuación se muestran los datos de texto de ejemplo para el reto 1. Escriba una función para:\n\n* Escribir el texto en minúsculas\n* Elimine los signos de puntuación\n* Elimine los espacios en blanco\n* Siéntase libre de reciclar los códigos que hemos utilizado más arriba.","metadata":{}},{"cell_type":"code","source":"challenge1_path = '/kaggle/input/data-tweets/example1.txt'\n\nwith open(challenge1_path, 'r') as file:\n    challenge1 = file.read()\n    \nprint(challenge1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:47.596115Z","iopub.execute_input":"2025-03-25T16:29:47.596561Z","iopub.status.idle":"2025-03-25T16:29:47.605191Z","shell.execute_reply.started":"2025-03-25T16:29:47.596528Z","shell.execute_reply":"2025-03-25T16:29:47.603930Z"}},"outputs":[{"name":"stdout","text":"\n\nThis is a text file that has some extra blankspace at the start and end. Blankspace is a catch-all term for spaces, tabs, newlines, and a bunch of other things that computers distinguish but to us all look like spaces, tabs and newlines.\n\n\nThe Python method called \"strip\" only catches blankspace at the start and end of a string. But it won't catch it in       the middle,\t\tfor example,\n\nin this sentence.\t\tOnce again, regular expressions will\n\nhelp\t\tus    with this.\n\n\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def clean_text(text):\n\n    # Step 1: Minúsculas\n    text = text.lower()\n\n    # Step 2: Usamos remove_punct para remover signos de puntuación\n    text = remove_punct(text)\n\n    # Step 3: Remove extra whitespace characters\n    text =  re.sub( blankspace_pattern, blankspace_repl,text)\n    text = text.strip()\n\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:50.319554Z","iopub.execute_input":"2025-03-25T16:29:50.319902Z","iopub.status.idle":"2025-03-25T16:29:50.325472Z","shell.execute_reply.started":"2025-03-25T16:29:50.319874Z","shell.execute_reply":"2025-03-25T16:29:50.324252Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Uncomment to apply the above function to challenge 1 text \nclean_text(challenge1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:53.326405Z","iopub.execute_input":"2025-03-25T16:29:53.326743Z","iopub.status.idle":"2025-03-25T16:29:53.333069Z","shell.execute_reply.started":"2025-03-25T16:29:53.326718Z","shell.execute_reply":"2025-03-25T16:29:53.331676Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'this is a text file that has some extra blankspace at the start and end blankspace is a catchall term for spaces tabs newlines and a bunch of other things that computers distinguish but to us all look like spaces tabs and newlines the python method called strip only catches blankspace at the start and end of a string but it wont catch it in the middle for example in this sentence once again regular expressions will help us with this'"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Procesos para tareas específicas\nAhora que ya conocemos las operaciones habituales de preprocesamiento, aún hay que tener en cuenta algunas operaciones adicionales. Nuestros datos de texto pueden requerir una normalización adicional en función del idioma, la fuente y el contenido de los datos.\n\nPor ejemplo, si trabajamos con documentos financieros, es posible que queramos normalizar los símbolos monetarios convirtiéndolos en dígitos. En nuestros datos de tuits, hay numerosos hashtags y URLs. Estos pueden sustituirse por marcadores de posición para simplificar el análisis posterior.\n\n\n## Demostración: Eliminar Hashtags y URLs\nAunque las URL, los hashtags y los números son informativos por derecho propio, a menudo no nos importa necesariamente el significado exacto de cada uno de ellos.\n\nAunque podríamos eliminarlas por completo, a menudo es informativo saber que existe una URL o un hashtag. En la práctica, sustituimos las URL y los hashtags individuales por un «símbolo» que conserva el hecho de que estas estructuras existen en el texto. Lo normal es utilizar simplemente las cadenas \"URL\" y \"HASHTAG\".\n\nComo estos tipos de texto suelen seguir una estructura regular, son un caso adecuado para utilizar expresiones regulares. Apliquemos estos patrones a los datos de los tweets.","metadata":{}},{"cell_type":"code","source":"# Print al ejemplo de tweet \nurl_tweet = tweets['text'][13]\nprint(url_tweet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:29:59.124326Z","iopub.execute_input":"2025-03-25T16:29:59.124650Z","iopub.status.idle":"2025-03-25T16:29:59.130571Z","shell.execute_reply.started":"2025-03-25T16:29:59.124624Z","shell.execute_reply":"2025-03-25T16:29:59.129309Z"}},"outputs":[{"name":"stdout","text":"@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# URL \nurl_pattern = r'(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])'\nurl_repl = ' URL '\nre.sub(url_pattern, url_repl, url_tweet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:30:01.634254Z","iopub.execute_input":"2025-03-25T16:30:01.634652Z","iopub.status.idle":"2025-03-25T16:30:01.645086Z","shell.execute_reply.started":"2025-03-25T16:30:01.634616Z","shell.execute_reply":"2025-03-25T16:30:01.642954Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"\"@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel  URL \""},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Hashtag\nhashtag_pattern = r'(?:^|\\s)[＃#]{1}(\\w+)'\nhashtag_repl = ' HASHTAG '\nre.sub(hashtag_pattern, hashtag_repl, url_tweet)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T16:30:05.164603Z","iopub.execute_input":"2025-03-25T16:30:05.165169Z","iopub.status.idle":"2025-03-25T16:30:05.176504Z","shell.execute_reply.started":"2025-03-25T16:30:05.165101Z","shell.execute_reply":"2025-03-25T16:30:05.174543Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"\"@VirginAmerica @virginmedia I'm flying your HASHTAG  HASHTAG  skies again! U take all the HASHTAG  away from travel http://t.co/ahlXHhKiyn\""},"metadata":{}}],"execution_count":27}]}